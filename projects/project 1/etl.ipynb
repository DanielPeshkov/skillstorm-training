{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pymssql\n",
    "import time\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "def connect_to_db():\n",
    "    conn = pymssql.connect(host=os.environ['db_host'], database=os.environ['db_name'])\n",
    "    cursor = conn.cursor()\n",
    "    return conn, cursor\n",
    "\n",
    "# Close database connection\n",
    "def close_db_connection(conn, cursor):\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Ticker Data From Polygon API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request data from api\n",
    "def call_api(ticker, info, start, end):\n",
    "    \n",
    "    # Creating Request\n",
    "    key = os.environ['polygon_api']\n",
    "    url = f'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/day/{start}/{end}?adjusted=true&sort=asc&apiKey={key}'\n",
    "\n",
    "    # Retrieving data\n",
    "    response = requests.get(url=url)\n",
    "    data = pd.json_normalize(response.json()['results'])\n",
    "\n",
    "    # Forrmat date column\n",
    "    data.t = data.t.apply(lambda x: datetime.fromtimestamp(x/1e3).date().strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Map useful column names\n",
    "    column_map = {\n",
    "    'c': 'Close', \n",
    "    'h': 'High', \n",
    "    'l': 'Low', \n",
    "    'n': 'Transactions', \n",
    "    'o': 'Open', \n",
    "    'otc': 'OTC', \n",
    "    't': 'Date', \n",
    "    'v': 'Volume', \n",
    "    'vw': 'Price' # Volume Weighted Average Price\n",
    "    }\n",
    "    data.columns = data.columns.map(column_map)\n",
    "\n",
    "    # Add missing dates between 2023-01-01 and Today\n",
    "    date_range = pd.date_range(start='2023-01-01', end=datetime.today().strftime('%Y-%m-%d'))\n",
    "    data.Date = data.Date.astype('datetime64[D]')\n",
    "\n",
    "    # Filter to only include data after 2023-01-01\n",
    "    data = data[data.Date >= '2023-01-01']\n",
    "\n",
    "    # Fill empty dates with most recent data\n",
    "    data = data.set_index('Date').reindex(date_range).resample('D').ffill().bfill().reset_index().rename(columns={'index':'Date'}).ffill()\n",
    "    \n",
    "    # Format date to YYYY-MM-DD\n",
    "    data.Date = data.Date.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Indices have no volume weighted price or volume\n",
    "    # Calculate average price\n",
    "    if 'Price' not in data.columns:\n",
    "        data['Price'] = (data.Open + data.High + data.Low + data.Close) / 4\n",
    "        data['Volume'] = None\n",
    "    \n",
    "    # Add ticker-specific data to dataframe\n",
    "    data['Investment Type'] = info['type']\n",
    "    data['Ticker'] = ticker\n",
    "    data['Company'] = info['name']\n",
    "    data = data[['Investment Type', 'Ticker','Company', 'Date', 'Price', 'Volume']]\n",
    "    data['amount'] = info['amount']\n",
    "\n",
    "    # Return resulting dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Preprocess with Calculated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add calculated columns to data\n",
    "def calculate_columns(data):\n",
    "\n",
    "    # 10 and 100 day moving averages\n",
    "    data['ma10'] = data.Price.rolling(window=10).mean()\n",
    "    data['ma100'] = data.Price.rolling(window=100).mean()\n",
    "\n",
    "    # Total and Percentage change (day over day)\n",
    "    data['change'] = data.Price.diff(periods=1)\n",
    "    data['pct_change'] = data.Price.pct_change()\n",
    "\n",
    "    # Fill NaN with None for SQL Server compatibility\n",
    "    data = data.replace({np.nan: None})\n",
    "    \n",
    "    # Return updated dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beta Coefficient calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta Coefficient\n",
    "def beta(data, market):\n",
    "    # Select common dates for comparison\n",
    "    common = pd.merge(data[['Price', 'Date']], market[['Price', 'Date']], on='Date', how='inner')\n",
    "\n",
    "    # Convert to percent change\n",
    "    target = common.Price_x.pct_change().dropna()\n",
    "    base = common.Price_y.pct_change().dropna()\n",
    "    \n",
    "    # Return Beta Coefficient\n",
    "    return statistics.covariance(target, base) / statistics.variance(base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Preprocessing, split data into tables, insert into OLAP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into database\n",
    "def insert_data(conn, cursor, data, market):\n",
    "\n",
    "\t# Ticker metrics for investment_agg_facts table\n",
    "\tfirst_price = data.iloc[0].Price\n",
    "\tlast_price = data.iloc[len(data)-1].Price\n",
    "\tfirst_date = data.iloc[0].Date\n",
    "\tlast_date = data.iloc[len(data)-1].Date\n",
    "\tbeta_val = beta(data, market)\n",
    "\n",
    "\t# Ticker info for investment_dimension table\n",
    "\tinvestments = data[['Ticker','Company', 'Investment Type']].drop_duplicates().apply(lambda x: x.str.title())\n",
    "\tinvestments['Ticker'] = investments['Ticker'].str.upper()\n",
    "\tinvestments['amount'] = data['amount']\n",
    "\tinvestments['shares'] = data['amount'] / first_price\n",
    "\tinvestments = [tuple(i) for i in investments.values]\n",
    "\n",
    "\t# Update investment_dimension table\n",
    "\tcursor.executemany(\"\"\"\n",
    "MERGE investment_dimension AS t\n",
    "USING (\n",
    "\tVALUES \n",
    "\t\t(%s, %s, %s, %d, %d)\n",
    "\t) AS s (ticker, company, investment_type, amount, shares)\n",
    "ON t.ticker = s.ticker\n",
    "WHEN NOT MATCHED BY target THEN\n",
    "\tINSERT VALUES (ticker, company, investment_type, amount, shares)\n",
    "WHEN MATCHED THEN\n",
    "\tUPDATE SET \n",
    "\t\tt.company = s.company, \n",
    "\t\tt.investment_type = s.investment_type,\n",
    "        t.amount = s.amount,\n",
    "\t\tt.shares = s.shares;\n",
    "\"\"\", investments)\n",
    "\t# Save data in SQL Server\n",
    "\tconn.commit()\n",
    "\n",
    "\t# Create map of ticker name to id\n",
    "\tcompany_map = {}\n",
    "\tcursor.execute(\"Select * FROM investment_dimension;\")\n",
    "\tfor id, ticker, company, investment_type, amount, shares in cursor.fetchall():\n",
    "\t\tcompany_map[ticker] = id\n",
    "\n",
    "\t# Map foreign key ticker id\n",
    "\tdata['investment_id'] = data['Ticker'].map(company_map)\n",
    "\n",
    "\t# Select necessary columns for price_facts table\n",
    "\tprices = data[['Price', 'Volume', 'investment_id', 'Date', 'ma10', 'ma100', 'change', 'pct_change']].copy()\n",
    "\n",
    "\t# Calculate value of portfolio investment from number of shares and price\n",
    "\tprices['value'] = investments[0][4] * prices['Price']\n",
    "\n",
    "\t# Calculate return of investment from value and original cost\n",
    "\tprices['return'] = prices['value'] - investments[0][3]\n",
    "\n",
    "\t# Calculate percent change weighted by portfolio fraction\n",
    "\tprices['weighted_pct'] = prices['pct_change'] * data['amount'] / 100000\n",
    "\n",
    "\t# Fill NaN with None for SQL Server Compatibility\n",
    "\tprices = prices.replace({np.nan: None})\n",
    "\tprices = [tuple(i) for i in prices.values]\n",
    "\n",
    "    # Update price_facts table\n",
    "\tcursor.executemany(\"\"\"\n",
    "MERGE price_facts AS t\n",
    "USING (\n",
    "\tVALUES\n",
    "\t\t(%d, %d, %d, %s, %d, %d, %d, %d, %d, %d, %d)\n",
    "\t) AS s (price, volume, investment_id, date, ma10, ma100, [change], pct_change, value, [return], weighted_pct)\n",
    "ON (t.date = s.date AND t.investment_id = s.investment_id)\n",
    "WHEN NOT MATCHED BY target THEN\n",
    "\tINSERT VALUES (price, volume, investment_id, date, ma10, ma100, [change], pct_change, value, [return], weighted_pct);\n",
    "\"\"\", prices)\n",
    "    \n",
    "\t# Update investment_agg_facts table\n",
    "\tcursor.execute(f\"\"\"\n",
    "MERGE investment_agg_facts AS t\n",
    "USING (\n",
    "    VALUES\n",
    "        ({company_map[data.Ticker.unique()[0]]}, {first_price}, {last_price}, '{first_date}', '{last_date}', {beta_val})    \n",
    "    ) AS s (invest_id, first_price, last_price, first_date, last_date, beta)\n",
    "ON t.invest_id = s.invest_id\n",
    "WHEN NOT MATCHED BY target THEN\n",
    "\tINSERT VALUES (invest_id, first_price, last_price, first_date, last_date, beta)\n",
    "WHEN MATCHED THEN\n",
    "\tUPDATE SET\n",
    "\t\tt.last_price = s.last_price, \n",
    "        t.last_date = s.last_date, \n",
    "\t\tt.beta = s.beta;\n",
    "\"\"\")\n",
    "\t# Save data in SQL Server\n",
    "\tconn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform and Load into OLAP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tickers and timeframe\n",
    "tickers = {'NVDA': {'type':'stock', 'name': 'Nvidia Corp', 'amount': 20000},\n",
    "           'CRWD': {'type':'stock', 'name': 'Crowdstrike Holdings Inc', 'amount': 15000}, \n",
    "           'MU': {'type':'stock', 'name': 'Micron Technology Inc', 'amount': 15000}, \n",
    "           'SATO': {'type':'etf', 'name': 'Invesco Alerian Galaxy Crypto Economy ETF', 'amount': 20000},\n",
    "           'SPY': {'type':'etf', 'name': 'SPDR S&P 500 ETF Trust', 'amount': 10000}, \n",
    "           'C:USDTRY': {'type':'forex', 'name': 'USD/TRY', 'amount': 10000}, \n",
    "           'X:SOLUSD': {'type':'crypto', 'name': 'SOL/USD', 'amount': 10000}, \n",
    "           'I:NDX': {'type':'index', 'name': 'Nasdaq-100', 'amount': 0}}\n",
    "start = '2023-01-01'\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Get broad market index data (NASDAQ 100)\n",
    "market_index = call_api('I:NDX', {'type':'index', 'name': 'Nasdaq-100', 'amount': 0}, start, end)\n",
    "\n",
    "# Connect to SQL Server\n",
    "conn, cursor = connect_to_db()\n",
    "\n",
    "# For each ticker\n",
    "for ind, (ticker, info) in enumerate(tickers.items()):\n",
    "    # Pause to stay within api rate limits\n",
    "    if (ind + 1) % 5 == 0:\n",
    "        time.sleep(60)\n",
    "\n",
    "    # Query API and Preprocess\n",
    "    data = call_api(ticker, info, start, end)\n",
    "\n",
    "    # Add calculated columns to data\n",
    "    data = calculate_columns(data)\n",
    "\n",
    "    # Insert into DB\n",
    "    insert_data(conn, cursor, data, market_index)\n",
    "\n",
    "# Close DB Connection\n",
    "close_db_connection(conn, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
